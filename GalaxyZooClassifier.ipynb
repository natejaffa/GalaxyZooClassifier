{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b7f32b",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc522e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the things\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e188d",
   "metadata": {},
   "source": [
    "# A bit of data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2af911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GalaxyID', 'Class1.1', 'Class1.2', 'Class1.3', 'Class2.1', 'Class2.2',\n",
      "       'Class3.1', 'Class3.2', 'Class4.1', 'Class4.2', 'Class5.1', 'Class5.2',\n",
      "       'Class5.3', 'Class5.4', 'Class6.1', 'Class6.2', 'Class7.1', 'Class7.2',\n",
      "       'Class7.3', 'Class8.1', 'Class8.2', 'Class8.3', 'Class8.4', 'Class8.5',\n",
      "       'Class8.6', 'Class8.7', 'Class9.1', 'Class9.2', 'Class9.3', 'Class10.1',\n",
      "       'Class10.2', 'Class10.3', 'Class11.1', 'Class11.2', 'Class11.3',\n",
      "       'Class11.4', 'Class11.5', 'Class11.6'],\n",
      "      dtype='object')\n",
      "Index(['GalaxyID', 'Class1.1', 'Class1.2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"/home/nate/CS82B_Final/training_solutions_rev1.csv\") #replace with appropriate filename\n",
    "print(labels.columns)\n",
    "labels = labels.loc[:,:\"Class1.2\"]\n",
    "print(labels.columns)\n",
    "labels.set_index(\"GalaxyID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e40d4e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           Class1.1  Class1.2\n",
      "GalaxyID                    \n",
      "100008    0.383147  0.616853\n",
      "100023    0.327001  0.663777\n",
      "100053    0.765717  0.177352\n",
      "100078    0.693377  0.238564\n",
      "100090    0.933839  0.000000\n",
      "...            ...       ...\n",
      "999948    0.510379  0.489621\n",
      "999950    0.901216  0.098784\n",
      "999958    0.202841  0.777376\n",
      "999964    0.091000  0.909000\n",
      "999967    0.767000  0.140000\n",
      "\n",
      "[61578 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(labels.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03afa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepath = \"/home/nate/CS82B_Final/images_training_rev1/\" #replace with appropriate filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17a121b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"smooth\", \"features/disk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9d5d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(galaxy):\n",
    "    for i,x in enumerate(labels.loc[galaxy]):\n",
    "        if x > 0.5: #there can't be multiple values greater than 0.5 and we want a good confidence for the label so I just chose that as the cutoff as well \n",
    "            return class_names[i]\n",
    "    return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bdda8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(galaxy):\n",
    "    image = Image.open(image_filepath + str(galaxy) + \".jpg\")\n",
    "    image = np.array(image.resize((32, 32)))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af080f",
   "metadata": {},
   "source": [
    "# One step of Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308cecea",
   "metadata": {},
   "source": [
    "## test_image = Image.open(image_filepath + \"100008.jpg\") \n",
    "print(np.array(test_image).shape)\n",
    "plt.imshow(test_image)\n",
    "plt.title(get_label(100008))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9e250",
   "metadata": {},
   "source": [
    "# Data preprocessing + data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f02f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "193\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n",
      "caught na\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(labels, labels, train_size=8000, random_state=42, test_size = 1600) \n",
    "#y values are useless cause they dont match with x values\n",
    "#these are recreated/fixed below\n",
    "\n",
    "temp = []\n",
    "rem = []\n",
    "count = 0\n",
    "for x in X_train.index:\n",
    "    a = get_label(x)\n",
    "    if type(a) == type(pd.NA): \n",
    "        print(\"caught na\") \n",
    "        count+=1\n",
    "        rem.append(x)\n",
    "    else:\n",
    "        temp.append(a)\n",
    "X_train = X_train.drop(rem)\n",
    "y_train = pd.DataFrame(temp)\n",
    "print(count)\n",
    "print(y_train[0].value_counts())\n",
    "\n",
    "temp = []\n",
    "rem = []\n",
    "for x in X_test.index:\n",
    "    a = get_label(x)\n",
    "    if type(a) == type(pd.NA):\n",
    "        print(\"caught na\")\n",
    "        rem.append(x)\n",
    "    else:\n",
    "        temp.append(a)\n",
    "X_test = X_test.drop(rem)\n",
    "y_test = pd.DataFrame(temp)\n",
    "\n",
    "X_train_knn= pd.DataFrame([get_image(x).flatten() for x in X_train.index])\n",
    "X_train= torch.tensor(np.array([get_image(x) for x in X_train.index]))\n",
    "\n",
    "\n",
    "X_test_knn = pd.DataFrame([get_image(x).flatten() for x in X_test.index])\n",
    "X_test = torch.tensor(np.array([get_image(x) for x in X_test.index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a88d20",
   "metadata": {},
   "source": [
    "# ML (knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb828a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'distance', 'p': 1, 'n_neighbors': 11}\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {'n_neighbors': [3, 7, 11, 15],\n",
    "                   'weights': ['uniform', 'distance'],\n",
    "                   'p': [1, 2]}\n",
    "knn = KNeighborsClassifier()\n",
    "rs = RandomizedSearchCV(knn, hyperparameters, scoring='f1_micro', n_jobs=-1, n_iter = 7)\n",
    "rs.fit(X_train_knn, np.ravel(y_train))\n",
    "model = rs.best_estimator_\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13da9b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score  0.7464698331193839\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "features/disk       0.79      0.73      0.76       860\n",
      "       smooth       0.70      0.76      0.73       698\n",
      "\n",
      "     accuracy                           0.75      1558\n",
      "    macro avg       0.75      0.75      0.75      1558\n",
      " weighted avg       0.75      0.75      0.75      1558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_knn)\n",
    "print(\"Accuracy score \", accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1a8e50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6976893453145058\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "features/disk       0.74      0.69      0.72       860\n",
      "       smooth       0.65      0.71      0.68       698\n",
      "\n",
      "     accuracy                           0.70      1558\n",
      "    macro avg       0.70      0.70      0.70      1558\n",
      " weighted avg       0.70      0.70      0.70      1558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "not_optimal = KNeighborsClassifier(n_neighbors = 3, weights = \"distance\", p = 2)\n",
    "not_optimal.fit(X_train_knn, np.ravel(y_train))\n",
    "\n",
    "pred = not_optimal.predict(X_test_knn)\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243f0ae",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6217bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up cnn archeticture",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb23a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training",
    "cel = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "cnn.train()\n",
    "\n",
    "numeric_train = [class_names.index(y) for y in y_train[0]]\n",
    "X_train = X_train.float()\n",
    "\n",
    "for x in range(5):\n",
    "    for x in range(0, len(X_train), 64):\n",
    "        galaxies = X_train[x:x+64].permute(0, 3, 1, 2)\n",
    "        labels = torch.tensor(numeric_train[x:x+64])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        values = cnn(galaxies)\n",
    "        loss = cel(values, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb991b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_test = [class_names.index(y) for y in y_test[0]]\n",
    "X_test = X_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef63c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "features/disk       0.81      0.85      0.83       860\n",
      "       smooth       0.80      0.75      0.77       698\n",
      "\n",
      "     accuracy                           0.80      1558\n",
      "    macro avg       0.80      0.80      0.80      1558\n",
      " weighted avg       0.80      0.80      0.80      1558\n",
      "\n",
      "Accuracy score: 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "#testing",
    "cnn.eval()\n",
    "total=0\n",
    "correct = 0\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    for x in range(0, len(X_test), 64):\n",
    "        galaxies = X_test[x:x+64].permute(0, 3, 1, 2)\n",
    "        labels = torch.tensor(numeric_test[x:x+64])\n",
    "\n",
    "        outputs = cnn(galaxies)\n",
    "        _, predicted = torch.max(outputs, 1) \n",
    "        for x in predicted:\n",
    "            pred.append(class_names[x.item()])\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(classification_report(y_test, pred))\n",
    "print(f\"Accuracy score: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e5348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
